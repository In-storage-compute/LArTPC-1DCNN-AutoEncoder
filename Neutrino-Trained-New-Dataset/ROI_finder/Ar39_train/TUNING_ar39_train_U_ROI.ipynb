{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import helper_functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SIGNALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wireplane = \"U\"\n",
    "np.random.seed(77)\n",
    "path = ('/home/vlian/Workspace/ar39_samples/processed/' +wireplane+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_adc_5_13 = np.load(path+'adc_5_13.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_adc_14_16 = np.load('/home/vlian/Workspace/ar39_new_samples/adc_14_16_U.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_adc_gt_eq_17 = np.load('/home/vlian/Workspace/ar39_new_samples/adc_gt_eq_17_U_ar39.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dataset_adc_14_16.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dataset_adc_gt_eq_17.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc_5_7 = dataset_adc_5_13['adc_5_7']\n",
    "adc_8_10 = dataset_adc_5_13['adc_8_10']\n",
    "adc_11_13 = dataset_adc_5_13['adc_11_13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc_14 = dataset_adc_14_16['adc_14']\n",
    "adc_15 = dataset_adc_14_16['adc_15']\n",
    "adc_16 = dataset_adc_14_16['adc_16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc_17 = dataset_adc_gt_eq_17['adc_17']\n",
    "adc_18 = dataset_adc_gt_eq_17['adc_18']\n",
    "adc_19 = dataset_adc_gt_eq_17['adc_19']\n",
    "adc_20 = dataset_adc_gt_eq_17['adc_20']\n",
    "adc_21 = dataset_adc_gt_eq_17['adc_21']\n",
    "adc_22 = dataset_adc_gt_eq_17['adc_22']\n",
    "adc_gt_22 = dataset_adc_gt_eq_17['adc_gt_22']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_data(adc_group, type_):\n",
    "    if type_:\n",
    "        num_samples = 54000\n",
    "    else:\n",
    "        num_samples = 18000\n",
    "    \n",
    "    x = adc_group[0][0:num_samples]\n",
    "    y = adc_group[1][0:num_samples]\n",
    "    \n",
    "    print(x.shape, y.shape)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc_5_7_x, adc_5_7_y = cut_data(adc_5_7, True)\n",
    "adc_8_10_x, adc_8_10_y = cut_data(adc_8_10, True)\n",
    "adc_11_13_x, adc_11_13_y = cut_data(adc_11_13, True)\n",
    "\n",
    "adc_14_x, adc_14_y = cut_data(adc_14, False)\n",
    "adc_15_x, adc_15_y = cut_data(adc_15, False)\n",
    "adc_16_x, adc_16_y = cut_data(adc_16, False)\n",
    "adc_17_x, adc_17_y = cut_data(adc_17, False)\n",
    "adc_18_x, adc_18_y = cut_data(adc_18, False)\n",
    "adc_19_x, adc_19_y = cut_data(adc_19, False)\n",
    "adc_20_x, adc_20_y = cut_data(adc_20, False)\n",
    "adc_21_x, adc_21_y = cut_data(adc_21, False)\n",
    "adc_22_x, adc_22_y = cut_data(adc_22, False)\n",
    "adc_gt_22_x, adc_gt_22_y = cut_data(adc_gt_22, True)\n",
    "\n",
    "del adc_5_7, adc_8_10, adc_11_13, adc_14, adc_15, adc_16, adc_17, adc_18, adc_19, adc_20, adc_21, adc_22, adc_gt_22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    fig = plt.figure(figsize=(8,1))\n",
    "    plt.plot(adc_8_10_x[i])\n",
    "    plt.plot(adc_8_10_y[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.empty((0,200))\n",
    "x_train = np.concatenate((x_train, adc_5_7_x))\n",
    "x_train = np.concatenate((x_train, adc_8_10_x))\n",
    "x_train = np.concatenate((x_train, adc_11_13_x))\n",
    "x_train = np.concatenate((x_train, adc_14_x))\n",
    "x_train = np.concatenate((x_train, adc_15_x))\n",
    "x_train = np.concatenate((x_train, adc_16_x))\n",
    "x_train = np.concatenate((x_train, adc_17_x))\n",
    "x_train = np.concatenate((x_train, adc_18_x))\n",
    "x_train = np.concatenate((x_train, adc_19_x))\n",
    "x_train = np.concatenate((x_train, adc_20_x))\n",
    "x_train = np.concatenate((x_train, adc_21_x))\n",
    "x_train = np.concatenate((x_train, adc_22_x))\n",
    "x_train = np.concatenate((x_train, adc_gt_22_x))\n",
    "\n",
    "y_train = np.empty((0,200))\n",
    "y_train = np.concatenate((y_train, adc_5_7_y))\n",
    "y_train = np.concatenate((y_train, adc_8_10_y))\n",
    "y_train = np.concatenate((y_train, adc_11_13_y))\n",
    "y_train = np.concatenate((y_train, adc_14_y))\n",
    "y_train = np.concatenate((y_train, adc_15_y))\n",
    "y_train = np.concatenate((y_train, adc_16_y))\n",
    "y_train = np.concatenate((y_train, adc_17_y))\n",
    "y_train = np.concatenate((y_train, adc_18_y))\n",
    "y_train = np.concatenate((y_train, adc_19_y))\n",
    "y_train = np.concatenate((y_train, adc_20_y))\n",
    "y_train = np.concatenate((y_train, adc_21_y))\n",
    "y_train = np.concatenate((y_train, adc_22_y))\n",
    "y_train = np.concatenate((y_train, adc_gt_22_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(300000,300000+10):\n",
    "    fig = plt.figure(figsize=(8,1))\n",
    "    plt.plot(x_train[i])\n",
    "    plt.plot(y_train[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    x_train, y_train = shuffle(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_truth_signals = np.ones(y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    fig = plt.figure(figsize=(8,1))\n",
    "    plt.title(str(max(y_train[i])) + ' -- ' + str(roi_truth_signals[i]) )\n",
    "    plt.plot(x_train[i])\n",
    "    plt.plot(y_train[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_grouping = f.adc_grouping(x_train, y_train)\n",
    "del check_grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_path = '/home/vlian/Workspace/more-noise/U/'\n",
    "noise_filenames = sorted([f for f in listdir(noise_path) if (isfile(join(noise_path, f)) and wireplane in f)])\n",
    "combined_noise = np.concatenate([np.load(noise_path+fname, mmap_mode='r') for fname in noise_filenames])\n",
    "\n",
    "noise_waveforms = f.get_std_waveforms(combined_noise, 200)\n",
    "roi_truth_noise = np.zeros(noise_waveforms.shape[0]) # for autoencoder\n",
    "print(noise_waveforms.shape, roi_truth_noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    noise_waveforms = shuffle(noise_waveforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_waveforms = noise_waveforms[:y_train.shape[0]]\n",
    "roi_truth_noise = roi_truth_noise[:y_train.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(noise_waveforms.shape, roi_truth_noise.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split - Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_train, roi_truth_signals, test_size=0.4, shuffle=True)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Val Split - Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, shuffle=True)\n",
    "print(x_train.shape, x_valid.shape, y_train.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split - Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_noise_train, x_noise_test, y_noise_train, y_noise_test = train_test_split(noise_waveforms, roi_truth_noise, test_size=0.3, shuffle=True)\n",
    "print(x_noise_train.shape, x_noise_test.shape, y_noise_train.shape, y_noise_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Val Split - Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_noise_train, x_noise_valid, y_noise_train, y_noise_valid = train_test_split(x_noise_train, y_noise_train, test_size=0.2, shuffle=True)\n",
    "print(x_noise_train.shape, x_noise_valid.shape, y_noise_train.shape, y_noise_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Signal + Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((x_train, x_noise_train))\n",
    "y_train = np.concatenate((y_train, y_noise_train))\n",
    "\n",
    "x_valid = np.concatenate((x_valid, x_noise_valid))\n",
    "y_valid = np.concatenate((y_valid, y_noise_valid))\n",
    "\n",
    "x_test = np.concatenate((x_test, x_noise_test))\n",
    "y_test = np.concatenate((y_test, y_noise_test))\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    x_valid, y_valid = shuffle(x_valid, y_valid)\n",
    "    x_test, y_test = shuffle(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = x_train.mean()\n",
    "std = x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Tuned_models/mean\"+wireplane+\"_nu_ROI\", mean)\n",
    "np.save(\"Tuned_models/scale\"+wireplane+\"_nu_ROI\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = (x_train-mean)/std\n",
    "x_valid_scaled = (x_valid-mean)/std\n",
    "x_test_scaled = (x_test-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = x_train_scaled.reshape(x_train_scaled.shape[0], x_train_scaled.shape[1], 1)\n",
    "x_valid_scaled = x_valid_scaled.reshape(x_valid_scaled.shape[0], x_valid_scaled.shape[1], 1)\n",
    "x_test_scaled = x_test_scaled.reshape(x_test_scaled.shape[0], x_test_scaled.shape[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, \\\n",
    "    Dropout, Dense,Flatten, AveragePooling1D, BatchNormalization\n",
    "\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_periods = 200\n",
    "def create_model(hp):\n",
    "    model = Sequential()  \n",
    "    #first convolutional block\n",
    "    model.add(Conv1D(filters=hp.Int('conv1_filter', \n",
    "                                    min_value = 16, \n",
    "                                    max_value=128, step=16), \n",
    "                    kernel_size=hp.Choice('conv1_kernel',\n",
    "                    values=[3,5]), strides=2, \n",
    "                    activation = \"relu\", input_shape=(time_periods,1)))\n",
    "    #model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "    #second convolutional block\n",
    "    model.add(Conv1D(filters=hp.Int('conv2_filter',\n",
    "                                   min_value=32, max_value=128, step=16),\n",
    "                     kernel_size=hp.Choice('conv2_kernal', values=[3,5]),\n",
    "                     strides=2, activation=\"relu\"))\n",
    "    #model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    #forth convolutional block                                      \n",
    "    model.add(Conv1D(filters=hp.Int('conv3_filter',\n",
    "                               min_value=64, max_value=128, step=16),\n",
    "                 kernel_size=hp.Choice('conv3_kernal', values=[7,9]),\n",
    "                 strides=2, activation = \"relu\"))\n",
    "    #model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dropout(0.2)) \n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "    model.add(Dense(1, activation=\"sigmoid\", name=\"wavrec_out\"))\n",
    "    adam = adam = tf.keras.optimizers.legacy.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(optimizer = adam, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(create_model, objective='val_accuracy',\n",
    "                                 max_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x_train_scaled, y_train, epochs=50,\n",
    "             validation_data=(x_valid_scaled, y_valid),\n",
    "             verbose=1)\n",
    "best_model=tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))                                                     \n",
    "plt.plot(history.history['accuracy'], \"g--\", label=\"Accuracy of training data\", antialiased=True)\n",
    "plt.plot(history.history['val_accuracy'], \"g\", label=\"Accuracy of validation data\", antialiased=True)\n",
    "plt.plot(history.history['loss'], \"r--\", label=\"Loss of training data\", antialiased=True)\n",
    "plt.plot(history.history['val_loss'], \"r\", label=\"Loss of validation data\", antialiased=True)\n",
    "plt.title('Model Accuracy and Loss')                                            \n",
    "plt.ylabel('Accuracy and Loss')                                                 \n",
    "plt.xlabel('Training Epoch')                                                    \n",
    "#plt.ylim(0)                                                                     \n",
    "plt.legend()                                                                    \n",
    "plt.show()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HERE\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Tuned_models/model\" + wireplane + \"plane_nu_ROI.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_scaled, y_test, batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ = x_train_scaled\n",
    "y_train_ = y_train\n",
    "\n",
    "x_valid_ = x_valid_scaled\n",
    "y_valid_ = y_valid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "all_infer = model.predict(x_test_scaled, batch_size=4096)\n",
    "all_y_test = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(all_y_test, all_infer)\n",
    "plt.plot(fpr_keras, tpr_keras, label='auc: ' + str(round(auc(fpr_keras, tpr_keras), 3)))\n",
    "plt.title(\"ROC Curve - Test Dataset Plane \" + wireplane )\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#cc_infer_signal = model.predict(cc_x_test_scaled[cc_y_test==1], batch_size=4096)\n",
    "#cc_infer_noise = model.predict(cc_x_test_scaled[cc_y_test==0], batch_size=4096)\n",
    "#es_infer_signal = model.predict(es_x_test_scaled[es_y_test==1], batch_size=4096)\n",
    "#es_infer_noise = model.predict(es_x_test_scaled[es_y_test==0], batch_size=4096)\n",
    "all_infer_signal = model.predict(x_test_scaled[y_test==1], batch_size=4096)\n",
    "all_infer_noise = model.predict(x_test_scaled[y_test==0], batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_infer_noise, range = (0,1), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_infer_signal, range = (0,1), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [out for out in all_infer if out >= 0.94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)/len(all_infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigs_truth = []\n",
    "sigs_pred = []\n",
    "\n",
    "noise_truth = []\n",
    "noise_pred = []\n",
    "\n",
    "for i, truth in enumerate(all_y_test):\n",
    "    if truth == 1:\n",
    "        sigs_truth.append(truth)\n",
    "        sigs_pred.append(all_infer[i])\n",
    "    else:\n",
    "        noise_truth.append(truth)\n",
    "        noise_pred.append(all_infer[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sigs_truth), len(sigs_pred))\n",
    "print(len(noise_truth), len(noise_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [out for out in sigs_pred if out >= 0.94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)/len(sigs_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [out for out in noise_pred if out < 0.94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)/len(noise_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tf]",
   "language": "python",
   "name": "conda-env-.conda-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
