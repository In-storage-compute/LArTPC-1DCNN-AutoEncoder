{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 23:12:30.448545: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-01 23:12:30.480756: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-01 23:12:30.620759: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-01 23:12:30.621462: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-01 23:12:31.338266: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# process data and save to memory as variables, not storage\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from PyPDF2 import PdfMerger\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wireplane='U'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes full raw data and extracts waveform of length nticks\n",
    "def extract_wave(data, nticks=200):\n",
    "    string = 'tck_'\n",
    "    waveforms = []\n",
    "    #Here I extract a column in each iteration and append to list\n",
    "    for i in range(nticks):\n",
    "        waveforms.append(data[string+str(i)].astype(np.int16))\n",
    "    #convert to numpy ndarray\n",
    "    waveforms = np.array(waveforms).astype(np.int16)\n",
    "    #since raws and columns are inverted we need to transpose it\n",
    "    return np.transpose(waveforms)\n",
    "\n",
    "# takes full raw data and returns waveform of length nticks\n",
    "# only keeps waves at a desired adc count \n",
    "def get_std_waveforms(data_noisy, data_clean, nticks=200, min_adc=5):\n",
    "    #Extract and scale waveform data (passthrough rn)\n",
    "    raw_waveforms_noisy = extract_wave(data_noisy, nticks)\n",
    "    raw_waveforms_clean = extract_wave(data_clean, nticks)\n",
    "    #print('before adc filter: ', raw_waveforms_noisy.shape, raw_waveforms_clean.shape)\n",
    "\n",
    "    noisy_ = []\n",
    "    clean_ = []\n",
    "\n",
    "    for i, wave in enumerate(raw_waveforms_clean):\n",
    "        if max(wave) >= min_adc:\n",
    "            noisy_.append(raw_waveforms_noisy[i])\n",
    "            clean_.append(wave)\n",
    "    \n",
    "    del raw_waveforms_noisy, raw_waveforms_clean\n",
    "\n",
    "    noisy_ = np.array(noisy_)\n",
    "    clean_ = np.array(clean_)\n",
    "\n",
    "    #print('after adc filter: ', noisy_.shape, clean_.shape)\n",
    "    #print(raw_waveforms) \n",
    "    #scaled_waveforms = waveform_scaler.fit_transform(raw_waveforms)\n",
    "    return noisy_, clean_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "# nuCC\n",
    "dir_noisy_nu_cc = '/home/vlian/Workspace/train_dune_lartpc_v2/nu_cc/'+wireplane+'/noisy_signal/'  # Directory to extract files\n",
    "dir_clean_nu_cc = '/home/vlian/Workspace/train_dune_lartpc_v2/nu_cc/'+wireplane+'/clean_signal/'  # Directory to extract files\n",
    "\n",
    "noisy_names_cc = os.listdir(dir_noisy_nu_cc)\n",
    "noisy_names_cc = sorted(noisy_names_cc)\n",
    "\n",
    "\n",
    "clean_names_cc = os.listdir(dir_clean_nu_cc)\n",
    "clean_names_cc = sorted(clean_names_cc)\n",
    "\n",
    "# nuES\n",
    "dir_noisy_nu_es = '/home/vlian/Workspace/train_dune_lartpc_v2/nu_es/'+wireplane+'/noisy_signal/'  # Directory to extract files\n",
    "dir_clean_nu_es = '/home/vlian/Workspace/train_dune_lartpc_v2/nu_es/'+wireplane+'/clean_signal/'  # Directory to extract files\n",
    "\n",
    "noisy_names_es = os.listdir(dir_noisy_nu_es)\n",
    "noisy_names_es = sorted(noisy_names_es)\n",
    "\n",
    "clean_names_es = os.listdir(dir_clean_nu_es)\n",
    "clean_names_es = sorted(clean_names_es)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 52\n",
      "188 188\n"
     ]
    }
   ],
   "source": [
    "print(len(noisy_names_cc), len(clean_names_cc))\n",
    "print(len(noisy_names_es), len(clean_names_es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snb-nucc-en0-U-signal-67877023-0-0.npy --- snb-nucc-en0-U-clnsig-67877023-0-0.npy\n",
      "snb-nues-en0-U-signal-101992-0-0.npy --- snb-nues-en0-U-clnsig-101992-0-0.npy\n"
     ]
    }
   ],
   "source": [
    "print(noisy_names_cc[0], '---', clean_names_cc[0])\n",
    "print(noisy_names_es[0], '---', clean_names_es[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seperate by energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wave_by_ENRG(energy_idx, noisy_filenames, clean_filenames, interaction_type=True):\n",
    "    if interaction_type:\n",
    "        noisy_path = dir_noisy_nu_cc\n",
    "        clean_path = dir_clean_nu_cc\n",
    "    else:\n",
    "        noisy_path = dir_noisy_nu_es\n",
    "        clean_path = dir_clean_nu_es\n",
    "\n",
    "    file_names_noisy = [file for file in noisy_filenames if 'en'+str(energy_idx) in file ]\n",
    "    file_names_clean = [file for file in clean_filenames if 'en'+str(energy_idx) in file ]\n",
    "\n",
    "    noisy_waveforms = np.empty((0, 200))\n",
    "    clean_waveforms = np.empty((0, 200))\n",
    "\n",
    "    for i, file_name in enumerate(file_names_noisy):\n",
    "        noisy_file_path = os.path.join(noisy_path, file_name)\n",
    "        clean_file_path = os.path.join(clean_path, file_names_clean[i])\n",
    "        \n",
    "\n",
    "        noisy = np.load(noisy_file_path)\n",
    "        clean = np.load(clean_file_path)\n",
    "\n",
    "        noisy_wf, clean_wf = get_std_waveforms(noisy, clean, nticks=200, min_adc=5)\n",
    "        \n",
    "        noisy_waveforms = np.concatenate((noisy_waveforms, noisy_wf))\n",
    "        clean_waveforms = np.concatenate((clean_waveforms, clean_wf))\n",
    "\n",
    "    return [noisy_waveforms, clean_waveforms]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_waveforms_nu_CC = []\n",
    "all_waveforms_nu_ES = []\n",
    "for i in range(10):\n",
    "    all_waveforms_nu_CC.append(get_wave_by_ENRG(i, noisy_names_cc, clean_names_cc))\n",
    "    all_waveforms_nu_ES.append(get_wave_by_ENRG(i, noisy_names_es, clean_names_es, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en 0 : nu_CC (4479, 200) (4479, 200) --- nu_ES (7080, 200) (7080, 200)\n",
      "en 1 : nu_CC (4377, 200) (4377, 200) --- nu_ES (6475, 200) (6475, 200)\n",
      "en 2 : nu_CC (4701, 200) (4701, 200) --- nu_ES (6353, 200) (6353, 200)\n",
      "en 3 : nu_CC (4869, 200) (4869, 200) --- nu_ES (6268, 200) (6268, 200)\n",
      "en 4 : nu_CC (4828, 200) (4828, 200) --- nu_ES (6346, 200) (6346, 200)\n",
      "en 5 : nu_CC (5891, 200) (5891, 200) --- nu_ES (6525, 200) (6525, 200)\n",
      "en 6 : nu_CC (5745, 200) (5745, 200) --- nu_ES (6588, 200) (6588, 200)\n",
      "en 7 : nu_CC (5919, 200) (5919, 200) --- nu_ES (6169, 200) (6169, 200)\n",
      "en 8 : nu_CC (5991, 200) (5991, 200) --- nu_ES (6860, 200) (6860, 200)\n",
      "en 9 : nu_CC (6809, 200) (6809, 200) --- nu_ES (6474, 200) (6474, 200)\n"
     ]
    }
   ],
   "source": [
    "for i, en in enumerate(all_waveforms_nu_CC):\n",
    "    print('en',i,':', 'nu_CC',en[0].shape, en[1].shape,'---','nu_ES', all_waveforms_nu_ES[i][0].shape, all_waveforms_nu_ES[i][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 200) (100000,)\n"
     ]
    }
   ],
   "source": [
    "noise_path = '/home/vlian/Workspace/train_dune_lartpc_v2/noise/'+wireplane+'/'\n",
    "noise_filenames = sorted([f for f in listdir(noise_path) if (isfile(join(noise_path, f)) and wireplane in f)])\n",
    "combined_noise = np.concatenate([np.load(noise_path+fname, mmap_mode='r') for fname in noise_filenames])\n",
    "\n",
    "noise_waveforms = extract_wave(combined_noise)\n",
    "roi_truth_noise = np.zeros(noise_waveforms.shape[0]) # for roi-finding\n",
    "print(noise_waveforms.shape, roi_truth_noise.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5_10_mean = np.load('../models_scales/mean_5_10' + wireplane + '_nu.npy')\n",
    "model_5_10_std = np.load('../models_scales/scale_5_10' + wireplane + '_nu.npy')\n",
    "\n",
    "model_5_15_mean = np.load('../models_scales/mean_5_15' + wireplane + '_nu.npy')\n",
    "model_5_15_std = np.load('../models_scales/scale_5_15' + wireplane + '_nu.npy')\n",
    "\n",
    "model_5_18_mean = np.load('../models_scales/mean_5_18' + wireplane + '_nu.npy')\n",
    "model_5_18_std = np.load('../models_scales/scale_5_18' + wireplane + '_nu.npy')\n",
    "\n",
    "model_60k_mean = np.load('../models_scales/mean_60k' + wireplane + '_nu.npy')\n",
    "model_60k_std = np.load('../models_scales/scale_60k' + wireplane + '_nu.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [[model_5_10_mean, model_5_10_std], [model_5_15_mean, model_5_15_std], \n",
    "           [model_5_18_mean, model_5_18_std], [model_60k_mean, model_60k_std]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5_10 = load_model('../ROI_ar39_models/model_5_10' + wireplane + 'plane_nu_ROI.h5')\n",
    "\n",
    "model_5_15 = load_model('../ROI_ar39_models/model_5_15' + wireplane + 'plane_nu_ROI.h5')\n",
    "\n",
    "model_5_18 = load_model('../ROI_ar39_models/model_5_18' + wireplane + 'plane_nu_ROI.h5')\n",
    "\n",
    "model_60k = load_model('../ROI_ar39_models/model_60k' + wireplane + 'plane_nu_ROI.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_5_10, model_5_15, model_5_18, model_60k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(idx, cnn_min):\n",
    "    model_idx = idx\n",
    "\n",
    "    noise_scaled = (noise_waveforms-scalers[model_idx][0])/scalers[model_idx][1]\n",
    "    infer = models[model_idx].predict(noise_scaled, verbose=0)\n",
    "    \n",
    "    return (len([i for i in infer if i > cnn_min])/len(infer))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print(round(eval_model(i, 0.999), 5), round(eval_model(i, 0.94), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_en(en_group_waveforms, model_idx, cnn_min):\n",
    "\n",
    "    waveforms_scaled = (en_group_waveforms-scalers[model_idx][0])/scalers[model_idx][1]\n",
    "    infer = models[model_idx].predict(waveforms_scaled, verbose=0)\n",
    "    \n",
    "    return (len([i for i in infer if i > cnn_min])/len(infer))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, signals_at_en in enumerate(all_waveforms_nu_ES):\n",
    "    print('en:', i)\n",
    "    for j in range(4):\n",
    "        #print('    model:', j)\n",
    "        print(round(eval_model_en(signals_at_en[0], j, 0.999), 2), round(eval_model_en(signals_at_en[0], j, 0.94), 2))\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5_10_AE = load_model('../AE_ar39_models/model_5_10' + wireplane + 'plane_nu_AE.h5')\n",
    "\n",
    "model_5_15_AE = load_model('../AE_ar39_models/model_5_15' + wireplane + 'plane_nu_AE.h5')\n",
    "\n",
    "model_5_18_AE = load_model('../AE_ar39_models/model_5_18' + wireplane + 'plane_nu_AE.h5')\n",
    "\n",
    "model_60k_AE = load_model('../AE_ar39_models/model_60k' + wireplane + 'plane_nu_AE.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_AE_check = load_model('../../../archive/AutoEncoder-Current/models/model_AE_2048_no_poolingUplane_nu.h5')\n",
    "mean_check = np.load('../../../archive/AutoEncoder-Current/models/mean_AE_np_U.npy')\n",
    "std_check = np.load('../../../archive/AutoEncoder-Current/models/std_AE_np_U.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_CC_energy = {0: '.028-5.50 MeV',\n",
    "                1: '5.50-7.60 MeV',\n",
    "                2: '7.60-10.0 MeV',\n",
    "                3: '10.0-12.0 MeV',\n",
    "                4: '12.0-15.0 MeV',\n",
    "                5: '15.0-17.0 MeV',\n",
    "                6: '17.0-20.0 MeV',\n",
    "                7: '20.0-24.0 MeV',\n",
    "                8: '24.0-29.0 MeV',\n",
    "                9: '29.0-85.0 MeV'\n",
    "                }\n",
    "\n",
    "nu_ES_energy = {0: '0.005-0.010 GeV',\n",
    "                1: '0.010-0.013 GeV',\n",
    "                2: '0.013-0.016 GeV',\n",
    "                3: '0.016-0.019 GeV',\n",
    "                4: '0.019-0.021 GeV',\n",
    "                5: '0.021-0.024 GeV',\n",
    "                6: '0.024-0.027 GeV',\n",
    "                7: '0.027-0.031 GeV',\n",
    "                8: '0.031-0.036 GeV',\n",
    "                9: '0.036-0.079 GeV',\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_single_pdf(x, y, predicted, interaction,energy, energy_range, wave_idx, pg_num):\n",
    "\n",
    "    fig, axs = plt.subplots(3,2, figsize=(20, 12), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .375, wspace=.1)\n",
    "\n",
    "    axes = axs.ravel()\n",
    "\n",
    "    for i in range(6):\n",
    "        index_ = i + wave_idx\n",
    "        wave_idx = index_\n",
    "        axes[i].set_title(interaction + ': ' + energy_range + ' --- (peak adc: ' + str(max(y[wave_idx])) + ')')\n",
    "        axes[i].plot(x[wave_idx], color='black', alpha=0.3, label='input')\n",
    "        axes[i].plot(y[wave_idx], color='blue', label='target')\n",
    "        axes[i].plot(predicted[wave_idx], color='m', label='prediction')\n",
    "        axes[i].legend(fontsize=12)\n",
    "    \n",
    "\n",
    "\n",
    "    plt.savefig('./plots/tmp/tmp' +str(pg_num) + '.pdf',\n",
    "                dpi=300,\n",
    "                bbox_inches='tight', pad_inches=0.75)\n",
    "    plt.close()\n",
    "\n",
    "    return wave_idx\n",
    "\n",
    "# creates and merges pdf, removes all single page pdfs from tmp folder\n",
    "def make_complete_pdf(x, y, predicted, interaction, energy, energy_range, num_pages):\n",
    "    wave_idx_ = 0\n",
    "    page_num = 0\n",
    "\n",
    "    while page_num < num_pages:\n",
    "        wave_idx_ = make_single_pdf(x, y, predicted, interaction, energy, energy_range, wave_idx_, page_num) + 1\n",
    "        page_num += 1\n",
    "\n",
    "    merger = PdfMerger()\n",
    "    path = './plots/tmp/'\n",
    "    pdf_files = [path+f for f in listdir(path) if (isfile(join(path, f)))]\n",
    "    print(pdf_files)\n",
    "    for pdf_file in pdf_files:\n",
    "        #Append PDF files\n",
    "        merger.append(pdf_file)\n",
    "    #merger.write('pdfs/plts_tmp/plts_' + wireplane + '_cnn_'+str(int(min_cnn*100)) + '-' + str(int(max_cnn*100)) + '_' + str(num_pages) +  'pages.pdf')\n",
    "    merger.write('./plots/plt_plots'+str(energy)+'.pdf')\n",
    "    merger.close()\n",
    "\n",
    "    for file in pdf_files:\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_ae(data_set, energy, energy_range,interaction, roi_model, ae_model, roi_scalers, ae_scalers):\n",
    "    waveform_noisy = data_set[energy][0]\n",
    "    print('aa: ', waveform_noisy.shape)\n",
    "    noisy_wave_scaled_ROI = (waveform_noisy-roi_scalers[0])/roi_scalers[1]\n",
    "    noisy_wave_scaled_AE = (waveform_noisy-ae_scalers[0])/ae_scalers[1]\n",
    "    \n",
    "    waveform_clean = data_set[energy][1]\n",
    "    clean_wave_scaled = (waveform_clean-ae_scalers[0])/ae_scalers[1]\n",
    "    counter = 0\n",
    "\n",
    "    noisy = np.empty((0, 200))\n",
    "    clean = np.empty((0, 200))\n",
    "    predicted = np.empty((0, 200))\n",
    "\n",
    "    for i in trange(len(waveform_noisy)):\n",
    "        wave_roi = noisy_wave_scaled_ROI[i:i+1]\n",
    "        if roi_model.predict(wave_roi, verbose=0) > 0.999:\n",
    "            wave_AE = noisy_wave_scaled_AE[i:i+1]\n",
    "            if max(waveform_clean[i:i+1][0]) < 1000:\n",
    "                ae_pred = ae_model.predict(wave_AE, verbose=0)\n",
    "                ae_pred = ae_pred.reshape(ae_pred.shape[0], ae_pred.shape[1])\n",
    "                pred = ae_pred*ae_scalers[1] + ae_scalers[0]\n",
    "                \n",
    "                noisy_wf = waveform_noisy[i]\n",
    "                noisy_wf = noisy_wf.reshape(1, 200)\n",
    "                noisy = np.concatenate((noisy, noisy_wf))\n",
    "                #print('debug: ', waveform_clean[i:i+1].shape, clean.shape)\n",
    "                clean = np.concatenate((clean, waveform_clean[i:i+1]))\n",
    "                #print('debug: ', pred.shape, predicted.shape)\n",
    "                predicted = np.concatenate((predicted, pred))\n",
    "    for j in range(10):\n",
    "        noisy, clean, predicted = shuffle(noisy, clean, predicted)\n",
    "    \n",
    "    \n",
    "    make_complete_pdf(noisy, clean, predicted, interaction, energy, energy_range, 20)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa:  (7080, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7080/7080 [06:58<00:00, 16.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./plots/tmp/tmp11.pdf', './plots/tmp/tmp1.pdf', './plots/tmp/tmp2.pdf', './plots/tmp/tmp3.pdf', './plots/tmp/tmp15.pdf', './plots/tmp/tmp0.pdf', './plots/tmp/tmp13.pdf', './plots/tmp/tmp4.pdf', './plots/tmp/tmp18.pdf', './plots/tmp/tmp19.pdf', './plots/tmp/tmp16.pdf', './plots/tmp/tmp9.pdf', './plots/tmp/tmp5.pdf', './plots/tmp/tmp17.pdf', './plots/tmp/tmp12.pdf', './plots/tmp/tmp14.pdf', './plots/tmp/tmp8.pdf', './plots/tmp/tmp7.pdf', './plots/tmp/tmp6.pdf', './plots/tmp/tmp10.pdf']\n",
      "aa:  (6475, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6475/6475 [06:28<00:00, 16.67it/s]\n"
     ]
    }
   ],
   "source": [
    "for energy_ in range(10):\n",
    "    roi_ae(all_waveforms_nu_ES, energy_, nu_ES_energy[energy_], 'nuES', model_60k, model_AE_check, [model_60k_mean, model_60k_std], [mean_check, std_check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_ae(data_set, energy, energy_range,interation, roi_model, ae_model, roi_scalers, ae_scalers, num_pred):\n",
    "    waveform_noisy = data_set[energy][0]\n",
    "    noisy_wave_scaled_ROI = (waveform_noisy-roi_scalers[0])/roi_scalers[1]\n",
    "    noisy_wave_scaled_AE = (waveform_noisy-ae_scalers[0])/ae_scalers[1]\n",
    "    \n",
    "    waveform_clean = data_set[energy][1]\n",
    "    clean_wave_scaled = (waveform_clean-ae_scalers[0])/ae_scalers[1]\n",
    "    counter = 0\n",
    "    for i in range(100000):\n",
    "        wave_roi = noisy_wave_scaled_ROI[i:i+1]\n",
    "        if roi_model.predict(wave_roi, verbose=0) > 0.999:\n",
    "            wave_AE = noisy_wave_scaled_AE[i:i+1]\n",
    "            if max(waveform_clean[i:i+1][0]) < 1000:\n",
    "                ae_pred = ae_model(wave_AE)\n",
    "                pred = ae_pred*ae_scalers[1] + ae_scalers[0]\n",
    "                print(max(waveform_clean[i:i+1][0]))\n",
    "                \n",
    "                fig = plt.figure(figsize=(8,3))\n",
    "                plt.title(interation + ': ' + energy_range + ' --- (peak adc: ' + str(max(waveform_clean[i:i+1][0])) + ')')\n",
    "                plt.plot(pred[0], color='m', label='pred')\n",
    "                plt.plot(waveform_clean[i:i+1][0], color='blue', label='target')\n",
    "                plt.ylabel('adc count')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "            \n",
    "                counter += 1\n",
    "            \n",
    "            if counter >= num_pred:\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
