{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train autoencoder WITHOUT using 1DCNN roi finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.utils import shuffle\n",
    "from PyPDF2 import PdfMerger\n",
    "import os\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wireplane = \"U\"\n",
    "np.random.seed(77)\n",
    "path = 'processed_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, wireplane):\n",
    "    x_train = np.load(path+'x_train_' + wireplane + '.npy')\n",
    "    x_test = np.load(path+'x_test_' + wireplane + '.npy')\n",
    "    y_train = np.load(path+'y_train_AE_' + wireplane + '.npy')\n",
    "    y_test = np.load(path+'y_test_AE_' + wireplane + '.npy')\n",
    "    \n",
    "    #split train and valid sets (40k train 10k valid) \n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "        x_train, y_train, test_size=0.2, shuffle=False\n",
    "    )\n",
    "    \n",
    "    mean = x_train.mean()\n",
    "    std = x_train.std()\n",
    "\n",
    "    x_train_scaled = (x_train-mean)/std\n",
    "    x_test_scaled = (x_test-mean)/std\n",
    "    x_valid_scaled = (x_valid-mean)/std\n",
    "    \n",
    "    y_train_scaled = (y_train-mean)/std\n",
    "    y_test_scaled = (y_test-mean)/std\n",
    "    y_valid_scaled = (y_valid-mean)/std\n",
    "\n",
    "    return x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled, x_valid_scaled, y_valid_scaled, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled, x_valid_scaled, y_valid_scaled, mean, std = load_data(path, wireplane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(6,9):\n",
    "    fig, (ax1) = plt.subplots(figsize=(12, 2), facecolor='white')\n",
    "    ax1.plot(x_train_scaled[idx],color='blue', label='signal+noise')\n",
    "    ax1.plot(y_train_scaled[idx],color='m',alpha=0.7, label='target')\n",
    "    ax1.set_title(\"waveform\", fontsize=15)\n",
    "    ax1.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D, Dropout, Dense,Flatten, AveragePooling1D\n",
    "from tensorflow.keras.layers import Input,  UpSampling1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, \\\n",
    "    Dropout, Dense,Flatten, AveragePooling1D, BatchNormalization\n",
    "#from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Conv1DTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_periods = 200\n",
    "input_wave = Input(shape=(time_periods, 1)) \n",
    "x = Conv1D(filters=16, kernel_size=3, strides=2, activation=\"relu\", input_shape=(time_periods,1))(input_wave)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    " \n",
    "# second convolutional block\n",
    "x = Conv1D(filters=32, kernel_size=5, strides=2, activation=\"relu\")(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "x = Conv1D(filters=64, kernel_size=9, strides=1, activation=\"relu\")(x)\n",
    "\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "encoded = Reshape((1, x.shape[1]))(x)\n",
    "\n",
    "\n",
    "x = UpSampling1D(size=3)(encoded)\n",
    "\n",
    "\n",
    "# first deconvolutional block\n",
    "x = Conv1DTranspose(filters=64, kernel_size=9, strides =1, activation=\"relu\")(x)\n",
    "x = UpSampling1D(size=2)(x)\n",
    "\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# second deconvolutional block\n",
    "x = Conv1DTranspose(filters=32, kernel_size=5, strides=2, activation=\"relu\")(x)\n",
    "\n",
    "x = UpSampling1D(size=2)(x) # increase the size to match the encoder\n",
    "\n",
    "decoded = Conv1DTranspose(filters=16, kernel_size=3, strides=2, activation=\"relu\")(x)\n",
    "decoded = Conv1DTranspose(filters=1, kernel_size=12, strides=1, activation='linear')(decoded)\n",
    "#print(decoded.shape())\n",
    "\n",
    "# create the model\n",
    "\n",
    "#decoded = tf.keras.layers.Cropping1D(cropping=(36, 37))(decoded)\n",
    "# create the model\n",
    "autoencoder = Model(input_wave, decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,layer in enumerate(autoencoder.layers):                                      \n",
    "  print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what happens when we unfreeze more layers of the 1dcnn\n",
    "for layer in autoencoder.layers:                                               \n",
    "    layer.trainable=True                                                                                                                     \n",
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_ = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history = autoencoder.fit(x_train_scaled,                                                              \n",
    "            y_train_scaled,                                                            \n",
    "            batch_size=batch_size_,                                              \n",
    "            epochs=100,                                                      \n",
    "            callbacks= [earlystop], #[NewCallback(alpha)], # callbacks=callbacks_list,\n",
    "            validation_data=(x_valid_scaled, y_valid_scaled),                                                                      \n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))                                                     \n",
    "plt.plot(history.history['loss'], \"r\", label=\"Loss of training data\", antialiased=True)\n",
    "plt.plot(history.history['val_loss'], \"r--\", label=\"Loss of validation data\", antialiased=True)\n",
    "plt.title('Model Loss',fontsize=15)                                            \n",
    "plt.ylabel('Loss (MSE)', fontsize=12)                                                 \n",
    "plt.xlabel('Training Epoch', fontsize=12)                                                                                                                       \n",
    "plt.legend(fontsize=12)                                                                    \n",
    "plt.show()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del x_train\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('./AE_experiment/model_AE_'+str(batch_size_)+'_mse_original' + wireplane + 'plane_nu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder = load_model('./AE_experiment/model_AE_'+str(batch_size_)+'_mse' + wireplane + 'plane_nu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.evaluate(x_test_scaled, y_test_scaled, batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.evaluate(x_train_scaled, y_train_scaled, batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.evaluate(x_valid_scaled, y_valid_scaled, batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae128 = load_model('./AE_models/model_AE_'+str(batch_size_)+'_mse' + wireplane + 'plane_nu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = autoencoder.predict(x_test_scaled, batch_size=4096)\n",
    "predictions = predictions.reshape(predictions.shape[0], predictions.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "x_test_ = std*x_test_scaled+mean\n",
    "y_test_ = y_test_scaled*std + mean\n",
    "\n",
    "\n",
    "pred = predictions*std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in prediction of AE and for every wave assigns 0 or 1\n",
    "# 0 --> predicted as noise\n",
    "# 1 --> pricicted as containing some kind of signals\n",
    "# note that this is crude and does not consider how close the predicted signal is from truth\n",
    "def label_predictions(ae_pred_wave):\n",
    "    label_ = 0\n",
    "    if max(abs(ae_pred_wave)) > 3:\n",
    "        label_ = 1\n",
    "    return label_\n",
    "\n",
    "\n",
    "def label_truths(wave):\n",
    "    label_ = 1\n",
    "    if max(abs(wave)) <= 3:\n",
    "        label_ = 0\n",
    "    return label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = [label_predictions(wave) for wave in pred]\n",
    "truth_labels = [label_truths(t_wave) for t_wave in y_test_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = load_model('ROI_models/model_'+wireplane+'plane_nu_ROI.h5')\n",
    "cnn_pred = cnn.predict(x_test_scaled, batch_size=4096)\n",
    "cnn_pred = cnn_pred.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100,200):\n",
    "    if max(abs(y_test_[i])) < 20 and sum(abs(y_test_[i])) !=0:\n",
    "        fig = plt.figure(figsize=(10,4))\n",
    "        plt.plot(x_test_[i], color='black', alpha=0.3, label='input')\n",
    "        plt.plot(y_test_[i], color='blue', alpha=0.9, label='truth ----- ' + str(truth_labels[i]))\n",
    "        plt.plot(pred[i], color='m', alpha=0.7, label='pred ----- ' + str(pred_labels[i]))\n",
    "        plt.title('CNN output: ' + str( round(cnn_pred[i], 3)))\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(truth_labels, pred_labels, drop_intermediate=False)\n",
    "roc_auc = auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 4))\n",
    "plt.plot(fpr, tpr, color='m', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', lw=2)\n",
    "#plt.xlim([0.0, 1.0])\n",
    "#plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_single_pdf(wave_idx, pg_num, min_cnn, max_cnn):\n",
    "\n",
    "    fig, axs = plt.subplots(3,2, figsize=(30, 18), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .375, wspace=.1)\n",
    "\n",
    "    axes = axs.ravel()\n",
    "\n",
    "    for i in range(6):\n",
    "        index_ = i + wave_idx\n",
    "        max_adc = int((max(x_test_[index_])))\n",
    "        \n",
    "        if not (max_adc < 20 and cnn_pred[index_] > min_cnn and cnn_pred[index_] <= max_cnn and sum(abs(y_test_[index_])) != 0):\n",
    "            while True:\n",
    "                index_ += 1\n",
    "                max_adc = int((max(x_test_[index_])))\n",
    "                \n",
    "                if (max_adc < 20 and cnn_pred[index_] > min_cnn and cnn_pred[index_] <= max_cnn and sum(abs(y_test_[index_])) != 0):\n",
    "                    break\n",
    "        wave_idx = index_\n",
    "\n",
    "\n",
    "        axes[i].plot(x_test_[index_], color='black',alpha=0.2, label = 'original input (adc_max: ' + str(max_adc) + ')')\n",
    "        axes[i].plot(y_test_[index_],color='blue', label='target', alpha=1)\n",
    "        axes[i].plot(pred128[index_], color='m', label='model_128  ---   ' + str(pred_labels128[index_]))\n",
    "        axes[i].plot(pred128_cmse[index_], color='green', label='model_128_cmse  ---   ' + str(pred_labels128_cmse[index_]))\n",
    "        axes[i].legend(fontsize=12)\n",
    "        axes[i].set_title('CNN output: ' + str(round(cnn_pred[index_], 4)) + ' --- [idx: ' + str(index_) + ']', size=15)\n",
    "        axes[i].set_ylabel('ADC', size=12)\n",
    "\n",
    "\n",
    "    plt.savefig('./AE_TEST/pdfs/tmp_plts/plts_cnn_page' + str(pg_num) +  '.pdf',\n",
    "                dpi=300,\n",
    "                bbox_inches='tight', pad_inches=0.75)\n",
    "    plt.close()\n",
    "\n",
    "    return wave_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates and merges pdf, removes all single page pdfs from tmp folder\n",
    "def make_complete_pdf(num_pages, min_cnn, max_cnn):\n",
    "    wave_idx_ = 0\n",
    "    page_num = 0\n",
    "\n",
    "    while page_num < num_pages:\n",
    "        wave_idx_ = make_single_pdf(wave_idx_, page_num, min_cnn, max_cnn) + 1\n",
    "        page_num += 1\n",
    "\n",
    "    merger = PdfMerger()\n",
    "    path = './AE_TEST/pdfs/tmp_plts/'\n",
    "    pdf_files = [path+f for f in listdir(path) if (isfile(join(path, f)))]\n",
    "    print(pdf_files)\n",
    "    for pdf_file in pdf_files:\n",
    "        #Append PDF files\n",
    "        merger.append(pdf_file)\n",
    "    #merger.write('pdfs/plts_tmp/plts_' + wireplane + '_cnn_'+str(int(min_cnn*100)) + '-' + str(int(max_cnn*100)) + '_' + str(num_pages) +  'pages.pdf')\n",
    "    merger.write('./AE_TEST/pdfs/'+wireplane+'/plts_' + wireplane + '_cnn_'+str(int(min_cnn*100)) + '-' + str(int(max_cnn*100)) + '_' + str(num_pages) +  'pages.pdf')\n",
    "    merger.close()\n",
    "\n",
    "    for file in pdf_files:\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_complete_pdf(10, 0.94, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ = 0.94\n",
    "prev = min_\n",
    "max_ = 1\n",
    "while min_ > 0:\n",
    "    min_ = min_ - 0.2 \n",
    "    make_complete_pdf(10, min_, prev)\n",
    "    prev = min_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
