{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "#!{sys.executable} -m pip install tensorflow-gpu==2.4\n",
    "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/vlian/anaconda3/envs/dune-1dcnn/lib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, select ADC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wireplane = \"U\"\n",
    "sig_name = wireplane+\"-signal\"\n",
    "cln_name = wireplane+\"-clnsig\"\n",
    "np.random.seed(42)\n",
    "nticks = 200\n",
    "max_mels = 11000\n",
    "min_edp = 50000\n",
    "ADC_MIN = 3\n",
    "ADC_MAX = 10\n",
    "waveform_scaler = StandardScaler()\n",
    "\n",
    "def extract_wave(data):\n",
    "    string = 'tck_'\n",
    "    waveforms = []\n",
    "    #Here I extract a column in each iteration and append to list\n",
    "    for i in range(nticks):\n",
    "        waveforms.append(data[string+str(i)].astype(np.int16))\n",
    "    #convert to numpy ndarray\n",
    "    waveforms = np.array(waveforms).astype(np.int16)\n",
    "    #since raws and columns are inverted we need to transpose it\n",
    "    return np.transpose(waveforms)\n",
    "\n",
    "def extract_peak(data):\n",
    "    #extract index of peak\n",
    "    idx = np.array([data['stp0'], data['adc0'], data['stp1'], data['adc1'], data['stp2'], data['adc2'], data['stp3'], data['adc3'], data['stp4'], data['adc4']])\n",
    "    #same as before\n",
    "    return np.transpose(idx)\n",
    "\n",
    "def extract_peak_info(data):\n",
    "    peaks_pos = [data['stp0'], data['stp1'], data['stp2'], data['stp3'], data['stp4']]\n",
    "    adcs = [data['adc0'], data['adc1'], data['adc2'], data['adc3'], data['adc4']]\n",
    "    return np.array(peaks_pos).T, np.array(adcs).T\n",
    "\n",
    "def extract_nel_info(data):\n",
    "    nels = [data['nel0'], data['nel1'], data['nel2'], data['nel3'], data['nel4']]\n",
    "    return np.array(nels).T\n",
    "\n",
    "def extract_edp_info(data):\n",
    "    edp = [data['edp0'], data['edp1'], data['edp2'], data['edp3'], data['edp4']]\n",
    "    return np.array(edp).T\n",
    "\n",
    "def filter_signals(data, clean_data, filter_adc_max=True):\n",
    "    #edp_mask = np.all(extract_edp_info(data)>min_edp, axis = 1)\n",
    "    #nel_mask = np.all(extract_nel_info(data)<max_mels, axis = 1)\n",
    "    #pd.DataFrame(np.all(extract_edp_info(data)>min_edp, axis = 1)).describe()\n",
    "    #print(edp_mask)\n",
    "    #print(nel_mask)\n",
    "    #filter_mask = nel_mask #np.logical_and(edp_mask,nel_mask) \n",
    "    filtered_data = data#[filter_mask]\n",
    "    cln_filtered_data = clean_data#[filter_mask]\n",
    "    \n",
    "    filtered_peak = extract_peak_info(filtered_data)[1]\n",
    "    if filter_adc_max:\n",
    "        peak_mask = np.any(filtered_peak>ADC_MIN, axis = 1)\n",
    "        peak_mask &= np.any(filtered_peak<ADC_MAX, axis = 1)\n",
    "    else:\n",
    "        peak_mask = np.any(filtered_peak>ADC_MIN, axis = 1)\n",
    "    \n",
    "    filtered_data = filtered_data[peak_mask]\n",
    "    cln_filtered_data = cln_filtered_data[peak_mask]\n",
    "    \n",
    "    return filtered_data, cln_filtered_data, filtered_peak\n",
    "\n",
    "def get_std_waveforms(data):\n",
    "    #Extract and scale waveform data (passthrough rn)\n",
    "    raw_waveforms = extract_wave(data)\n",
    "    #print(raw_waveforms) \n",
    "    #scaled_waveforms = waveform_scaler.fit_transform(raw_waveforms)\n",
    "    return raw_waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Training Data\n",
    "#path = \"../../dunesnb/1dcnn/train/train/nu_cc/\"\n",
    "#path2 = \"../../dunesnb/1dcnn/train/train/nu_es/\"\n",
    "\n",
    "# NEW DATA SET WITH\n",
    "path_cc = \"../../Workspace/new_data/train_v1/nu_cc/\"\n",
    "path_es = \"../../Workspace/new_data/train_v1/nu_es/\"\n",
    "\n",
    "filenames1 = [path_cc+f for f in listdir(path_cc) if (isfile(join(path_cc, f)) and sig_name in f)]\n",
    "clean_filenames1 = [path_cc+f for f in listdir(path_cc) if (isfile(join(path_cc, f)) and cln_name in f)]\n",
    "filenames2 = [path_es+f for f in listdir(path_es) if (isfile(join(path_es, f)) and sig_name in f)]\n",
    "clean_filenames2 = [path_es+f for f in listdir(path_es) if (isfile(join(path_es, f)) and cln_name in f)]\n",
    "\n",
    "filenames =  filenames1+filenames2\n",
    "clean_filenames = clean_filenames1+clean_filenames2\n",
    "\n",
    "combined_data = np.concatenate([np.load(fname) for fname in filenames])\n",
    "combined_clean_data = np.concatenate([np.load(fname) for fname in clean_filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_path = \"../../Workspace/new_data/train_v1/noise/\"\n",
    "noise_filenames = [f for f in listdir(noise_path) if (isfile(join(noise_path, f)) and wireplane in f)]\n",
    "print(len(noise_filenames))\n",
    "\n",
    "combined_noise = np.concatenate([np.load(noise_path+fname) for fname in noise_filenames])\n",
    "print(len(combined_noise))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Noise Data Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "print(combined_data.shape[0])\n",
    "#Filter out tiny signals < ADC_MIN, but leave big signals to test on (incl > ADC_MAX)\n",
    "combined_data, combined_clean_data, peak = filter_signals(combined_data, combined_clean_data, False)\n",
    "print(combined_data.shape[0])\n",
    "\n",
    "#split train and test sets (~50k ea before filtering) \n",
    "combined_data, x_test_data, combined_clean_data, x_test_clean  = train_test_split(\n",
    "    combined_data, combined_clean_data, test_size=0.5, shuffle=True\n",
    ")\n",
    "print(combined_data.shape[0])\n",
    "#filter data and extract waveforms of filtered data\n",
    "combined_data, combined_clean_data, peak = filter_signals(combined_data, combined_clean_data, True)\n",
    "signal_waveforms = get_std_waveforms(combined_data)\n",
    "print(combined_data.shape[0])\n",
    "#extract waveforms of noise\n",
    "noise_waveforms = get_std_waveforms(combined_noise)\n",
    "\n",
    "#extract waveforms of test data\n",
    "test_signal_waveforms = get_std_waveforms(x_test_data)\n",
    "print(test_signal_waveforms.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_signal_waveforms.shape, signal_waveforms.shape, noise_waveforms.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(5):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(30, 4))\n",
    "    ax1.plot(signal_waveforms[idx], color='blue')\n",
    "\n",
    "    ax2.plot(noise_waveforms[idx], color='orange')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate y data (assuming all radiologicals contain signal, all noise does not)\n",
    "y_noise_full = np.zeros(noise_waveforms.shape[0])\n",
    "y_signal = np.ones(signal_waveforms.shape[0])\n",
    "y_test_signal = np.ones(test_signal_waveforms.shape[0])\n",
    "\n",
    "# split test and train noise datasets (50k)\n",
    "x_noise_train, x_noise_test, y_noise_train, y_noise_test = train_test_split(\n",
    "    noise_waveforms, y_noise_full, test_size=0.5, shuffle=True\n",
    ")\n",
    "\n",
    "#Shuffle signal waveforms to be safe\n",
    "signal_waveforms, y_signal = shuffle(signal_waveforms,y_signal)\n",
    "\n",
    "#Shuffle test waveformst to be safe\n",
    "x_test, y_test = shuffle(test_signal_waveforms,y_test_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_noise_train.shape, signal_waveforms.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(14205-4, 14205):\n",
    "    fig, (ax1) = plt.subplots(figsize=(15, 4))\n",
    "    ax1.plot(signal_waveforms[idx], color='blue', label= \"target: \" + str(y_signal[idx]))\n",
    "    ax1.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(4):\n",
    "    fig, (ax1) = plt.subplots(figsize=(15, 4))\n",
    "    ax1.plot(x_noise_train[idx], color='blue', label= \"target: \" + str(y_noise_train[idx]))\n",
    "    ax1.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select First n signal samples from (shuffled) set of signals where n = noise samples for balanced train set \n",
    "x_train = np.concatenate((signal_waveforms[:int(x_noise_train.shape[0])], x_noise_train))\n",
    "y_train = np.concatenate((y_signal[:int(x_noise_train.shape[0])], y_noise_train))\n",
    "\n",
    "x_test = np.concatenate((x_test[:int(x_noise_test.shape[0])], x_noise_test))\n",
    "y_test = np.concatenate((y_test_signal[:int(x_noise_test.shape[0])], y_noise_test))\n",
    "\n",
    "\n",
    "# extra train shuffle for good measure \n",
    "x_train, y_train = shuffle(x_train,y_train)\n",
    "# extra test shuffle for good measure \n",
    "x_test, y_test = shuffle(x_test,y_test)\n",
    "\n",
    "#split train and valid sets (40k train 10k valid) \n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train, y_train, test_size=0.2, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = x_train.mean()\n",
    "std = x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = (x_train-mean)/std\n",
    "x_valid_scaled = (x_valid-mean)/std\n",
    "x_test_scaled = (x_test-mean)/std\n",
    "#cc_x_test_scaled = (cc_x_test-mean)/std \n",
    "#es_x_test_scaled = (es_x_test-mean)/std \n",
    "time_periods = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"models/mean_\"+wireplane+\"_nu\", mean)\n",
    "np.save(\"models/scale_\"+wireplane+\"_nu\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 632,
     "status": "ok",
     "timestamp": 1602697152760,
     "user": {
      "displayName": "Lorenzo Uboldi",
      "photoUrl": "",
      "userId": "12025999408021597208"
     },
     "user_tz": -120
    },
    "id": "8Kv4B_L4gmMF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, \\\n",
    "    Dropout, Dense,Flatten, AveragePooling1D, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D-CNN LArTPC Waveform Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "executionInfo": {
     "elapsed": 6059,
     "status": "ok",
     "timestamp": 1602697386319,
     "user": {
      "displayName": "Lorenzo Uboldi",
      "photoUrl": "",
      "userId": "12025999408021597208"
     },
     "user_tz": -120
    },
    "id": "Qy2CLcCzgmMK",
    "outputId": "bde22703-bb05-4503-976c-fa68081e1c69"
   },
   "outputs": [],
   "source": [
    "time_periods = 200\n",
    "def create_model():\n",
    "  model = Sequential()  \n",
    "  #first convolutional block\n",
    "  model.add(Conv1D(filters=16, kernel_size=3, strides=2, activation = \"relu\", input_shape=(time_periods,1)))\n",
    "  model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "  #second convolutional block\n",
    "  model.add(Conv1D(filters=32, kernel_size=5, strides=2, activation = \"relu\"))\n",
    "  model.add(MaxPooling1D(pool_size=2))\n",
    "  model.add(Dropout(0.1))\n",
    "  \n",
    "  #forth convolutional block                                      \n",
    "  model.add(Conv1D(filters=64, kernel_size=9, activation = \"relu\"))\n",
    "  model.add(GlobalMaxPooling1D())\n",
    "  model.add(Dropout(0.2)) \n",
    "    \n",
    "  model.add(Flatten())\n",
    "\n",
    "  \n",
    " \n",
    "  model.add(Dense(1, activation=\"sigmoid\", name=\"wavrec_out\"))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "#lr=0.001\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer = adam, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1602697394483,
     "user": {
      "displayName": "Lorenzo Uboldi",
      "photoUrl": "",
      "userId": "12025999408021597208"
     },
     "user_tz": -120
    },
    "id": "ck6Dc8zpgmMQ"
   },
   "outputs": [],
   "source": [
    "x_train_scaled = x_train_scaled.reshape(x_train_scaled.shape[0], x_train_scaled.shape[1], 1)\n",
    "#cc_x_test_scaled = cc_x_test_scaled.reshape(cc_x_test_scaled.shape[0], cc_x_test_scaled.shape[1], 1)\n",
    "#es_x_test_scaled = es_x_test_scaled.reshape(es_x_test_scaled.shape[0], es_x_test_scaled.shape[1], 1)\n",
    "x_valid_scaled = x_valid_scaled.reshape(x_valid_scaled.shape[0], x_valid_scaled.shape[1], 1)\n",
    "x_test_scaled = x_test_scaled.reshape(x_test_scaled.shape[0], x_test_scaled.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_scaled.shape, x_valid_scaled.shape, x_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746
    },
    "executionInfo": {
     "elapsed": 190700,
     "status": "ok",
     "timestamp": 1602697588909,
     "user": {
      "displayName": "Lorenzo Uboldi",
      "photoUrl": "",
      "userId": "12025999408021597208"
     },
     "user_tz": -120
    },
    "id": "pvebeWPOgmMU",
    "outputId": "c59d02f0-c33a-40be-a52a-eef5f7409d69"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(x_train_scaled,                                                              \n",
    "                    y_train,                                                            \n",
    "                    batch_size=2048,                                              \n",
    "                    epochs=100,      \n",
    "                    \n",
    "                   # epochs=30, \n",
    "                    #epochs = 6,\n",
    "                    callbacks=[earlystop],\n",
    "                     # callbacks=callbacks_list,                         \n",
    "                    validation_data=(x_valid_scaled, y_valid),                                               \n",
    "                    verbose=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "executionInfo": {
     "elapsed": 710,
     "status": "ok",
     "timestamp": 1602697613662,
     "user": {
      "displayName": "Lorenzo Uboldi",
      "photoUrl": "",
      "userId": "12025999408021597208"
     },
     "user_tz": -120
    },
    "id": "KagllrzUgmMZ",
    "outputId": "0a5d4266-3904-4eda-9d3e-6db6aa89664e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))                                                     \n",
    "plt.plot(history.history['accuracy'], \"g--\", label=\"Accuracy of training data\", antialiased=True)\n",
    "plt.plot(history.history['val_accuracy'], \"g\", label=\"Accuracy of validation data\", antialiased=True)\n",
    "plt.plot(history.history['loss'], \"r--\", label=\"Loss of training data\", antialiased=True)\n",
    "plt.plot(history.history['val_loss'], \"r\", label=\"Loss of validation data\", antialiased=True)\n",
    "plt.title('Model Accuracy and Loss')                                            \n",
    "plt.ylabel('Accuracy and Loss')                                                 \n",
    "plt.xlabel('Training Epoch')                                                    \n",
    "#plt.ylim(0)                                                                     \n",
    "plt.legend()                                                                    \n",
    "plt.show()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del x_train\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"models/model_\" + wireplane + \"plane_nu.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test_scaled, y_test, batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ = x_train_scaled\n",
    "y_train_ = y_train\n",
    "\n",
    "x_valid_ = x_valid_scaled\n",
    "y_valid_ = y_valid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "infer = model.predict(x_train_, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_train_, infer>0.5)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2 = confusion_matrix(y_train_, infer>0.9)\n",
    "sns.heatmap(cm2, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_for_plot = 0\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "plt.plot(y_train,color='orange',alpha=0.5, label='True')\n",
    "plt.plot(infer,color='blue',alpha=0.7, label='predicted')\n",
    "plt.xlim(start_for_plot, start_for_plot + 200)\n",
    "plt.title(\"infer\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_train_, infer)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auc_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"results/false_positive_\" + wireplane + \"_train\", fpr_keras)\n",
    "np.save(\"results/true_positive_\" + wireplane + \"_train\", tpr_keras)\n",
    "np.save(\"results/thresholds_\" + wireplane + \"_train\", thresholds_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "infer = model.predict(x_valid_, batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmv = confusion_matrix(y_valid_, infer>0.5)\n",
    "sns.heatmap(cmv, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmv2 = confusion_matrix(y_valid_, infer>0.9)\n",
    "sns.heatmap(cmv2, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_for_plot = 4000\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "plt.plot(y_valid_,color='orange',alpha=0.5, label='True')\n",
    "plt.plot(infer,color='blue',alpha=0.7, label='predicted')\n",
    "plt.xlim(start_for_plot, start_for_plot + 200)\n",
    "plt.title(\"infer\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_valid_, infer)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "print(auc_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"results/false_positive_\" + wireplane + \"_valid\", fpr_keras)\n",
    "np.save(\"results/true_positive_\" + wireplane + \"_valid\", tpr_keras)\n",
    "np.save(\"results/thresholds_\" + wireplane + \"_valid\", thresholds_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr_keras, tpr_keras, label='auc: ' + str(round(auc_keras,3)))\n",
    "plt.title(\"ROC Curve - Validation Dataset\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "all_infer = model.predict(x_test_scaled, batch_size=4096)\n",
    "all_y_test = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all1 = confusion_matrix(all_y_test, all_infer>0.5)\n",
    "sns.heatmap(all1, annot=True)\n",
    "plt.title(\"Confusion Matrix - Test Dataset Plane \" + wireplane)\n",
    "plt.xlabel(\"Predicted Class (>0.5)\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_for_plot = 4000\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "plt.plot(all_y_test,color='orange',alpha=0.5, label='True')\n",
    "plt.plot(all_infer,color='blue',alpha=0.7, label='predicted')\n",
    "plt.xlim(start_for_plot, start_for_plot + 200)\n",
    "plt.title(\"infer\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(all_y_test, all_infer)\n",
    "plt.plot(fpr_keras, tpr_keras, label='auc: ' + str(round(auc(fpr_keras, tpr_keras), 3)))\n",
    "plt.title(\"ROC Curve - Test Dataset Plane \" + wireplane )\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#cc_infer_signal = model.predict(cc_x_test_scaled[cc_y_test==1], batch_size=4096)\n",
    "#cc_infer_noise = model.predict(cc_x_test_scaled[cc_y_test==0], batch_size=4096)\n",
    "#es_infer_signal = model.predict(es_x_test_scaled[es_y_test==1], batch_size=4096)\n",
    "#es_infer_noise = model.predict(es_x_test_scaled[es_y_test==0], batch_size=4096)\n",
    "all_infer_signal = model.predict(x_test_scaled[y_test==1], batch_size=4096)\n",
    "all_infer_noise = model.predict(x_test_scaled[y_test==0], batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_infer_noise, range = (0,1), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_infer_signal, range = (0,1), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Small windows.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:51:29) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "0953303bb76e642cf0da4dd84c14ec5ff8cbb4c1b534b77010e5be534f549796"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
